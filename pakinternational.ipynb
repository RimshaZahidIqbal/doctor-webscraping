{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# Define the URL of the page to scrape\n",
    "url = \"https://pih.com.pk/doctors\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Define the doctor types of interest\n",
    "doctor_types = [\n",
    "    \"PSYCHIATRIST\",\n",
    "    \"NEUROLOGIST\",\n",
    "    \"DEVELOPMENTAL PEDIATRICIAN\",\n",
    "    \"CLINICAL PSYCHOLOGIST\",\n",
    "    \"OCCUPATIONAL THERAPIST\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store doctor data\n",
    "doctor_data = []\n",
    "\n",
    "# Find all doctor sections in the HTML\n",
    "for section in soup.find_all(\"div\", class_=\"elementor-column\"):\n",
    "    # Extract the doctor's type\n",
    "    doctor_type_elem = section.find(\"h6\", class_=\"elementor-heading-title\")\n",
    "    if doctor_type_elem:\n",
    "        doctor_type = doctor_type_elem.get_text(strip=True)\n",
    "        if doctor_type.upper() in doctor_types:\n",
    "            # Extract doctor's name\n",
    "            name_elem = section.find(\"h3\", class_=\"elementor-heading-title\")\n",
    "            name = name_elem.get_text(strip=True) if name_elem else \"N/A\"\n",
    "            \n",
    "            # Extract doctor's image URL\n",
    "            img_elem = section.find(\"img\")\n",
    "            img_url = img_elem['src'] if img_elem else \"N/A\"\n",
    "            \n",
    "            # Extract other details\n",
    "            details_elem = section.find(\"p\")\n",
    "            details = details_elem.get_text(strip=True) if details_elem else \"N/A\"\n",
    "            \n",
    "            # Parse the details to extract specific information\n",
    "            lines = details.split('\\n')\n",
    "            education = lines[0].strip() if len(lines) > 0 else \"N/A\"\n",
    "            position = lines[1].strip() if len(lines) > 1 else \"N/A\"\n",
    "            \n",
    "            # Assuming timing details are in a fixed format\n",
    "            timing_details = lines[2].strip() if len(lines) > 2 else \"N/A\"\n",
    "            days = []\n",
    "            timing = {}\n",
    "            if 'Mon' in timing_details:\n",
    "                days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
    "                timing = {\n",
    "                    \"Monday\": timing_details.split(\"–\")[-1].strip(),\n",
    "                    \"Tuesday\": timing_details.split(\"–\")[-1].strip(),\n",
    "                    \"Wednesday\": timing_details.split(\"–\")[-1].strip(),\n",
    "                    \"Thursday\": timing_details.split(\"–\")[-1].strip(),\n",
    "                    \"Friday\": timing_details.split(\"–\")[-1].strip(),\n",
    "                    \"Saturday\": timing_details.split(\"–\")[-1].strip()\n",
    "                }\n",
    "            \n",
    "            # Add the doctor data to the list\n",
    "            doctor_data.append({\n",
    "                \"name\": name,\n",
    "                \"education\": education,\n",
    "                \"hospital\": \"Not specified\",\n",
    "                \"position\": position,\n",
    "                \"clinic\": {\n",
    "                    \"days\": days,\n",
    "                    \"timing\": timing\n",
    "                }\n",
    "            })\n",
    "\n",
    "# Print the scraped doctor data\n",
    "print(json.dumps(doctor_data, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
